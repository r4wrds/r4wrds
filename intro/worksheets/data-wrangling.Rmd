---
### Click the RUN DOCUMENT 
### (the green "Play" button") in RStudio to run worksheet!
title: "Data Wrangling"
author: "R. Peek"
output: 
  learnr::tutorial:
    df_print: default
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(here)
library(tidyverse)
knitr::opts_chunk$set(echo = FALSE, comment = "")
stations <- read_csv("https://github.com/r4wrds/r4wrds/raw/worksheet-wrangling/intro/data/calenviroscreen/sac_county_crosswalk_to_gw_stations.csv")



```

<br>

This worksheet will help you work through some examples of some common data wrangling skills you may need to use. In particular, how to work with different types of data, join them, and summarize them.

You can write code into the code boxes and click the "**Run Document**" box to interact or answer the prompts. Some boxes may have __*Hints*__, click the box to find out more!

# Data Wrangling

At the root of most data science is the need to pull or import different types of data onto your computer, do something with that data to clean and summarize it, and then save the updated dataset for visualization and reporting. This process is repeated everywhere, and there are often many approaches and tools we can use. Let's focus on an example of pulling some spatial data and a spreadsheet to compare and contrast data.

## Import Data

We covered a number of different ways to import data in R in the lesson on [importing and exporting data](https://www.r4wrds.com/intro/m_importing_and_exporting_data.html).

Let's import or download a `csv` from a web path, and a shapefile from a zipped file, bring both into our R environment, and do some tidying.

If we know a webpath, how do we use it to import our data with the `read_csv` function?

```{r get-stations, exercise = TRUE}

webpath <- "https://github.com/r4wrds/r4wrds/raw/worksheet-wrangling/intro/data/calenviroscreen/sac_county_crosswalk_to_gw_stations.csv"

stations <- read_csv(___)

```

```{r get-stations-hint}

webpath <- "https://github.com/r4wrds/r4wrds/raw/worksheet-wrangling/intro/data/calenviroscreen/sac_county_crosswalk_to_gw_stations.csv"

stations <- read_csv(file = ___)

```

```{r get-stations-solution}

webpath <- "https://github.com/r4wrds/r4wrds/raw/worksheet-wrangling/intro/data/calenviroscreen/sac_county_crosswalk_to_gw_stations.csv"

stations <- read_csv(webpath)

```

Once we have our data, let's inspect it a bit more.

```{r}
glimpse(stations)
```

 - How many `unique` stations (`STN_ID`) are in this dataset? 
 - How many `distinct` `ZIP` codes are in this dataset?
 - Which `ZIP` code has the most stations?

```{r sta-query, exercise = TRUE}

length(unique(stations$STN_ID)) # n = 494
stations %>% distinct(STN_ID) %>% tally() # same!

stations %>% distinct(ZIP) %>% tally() # same!

stations %>% group_by(ZIP) %>% tally() %>% 
  arrange(desc(n))

```

```{r sta-query-hint-1}

# two ways to get the unique or distinct
unique(___) # how do we count how many are in this list?

```

```{r sta-query-hint-2}

# can count the length of a vector with length
length(unique(___))

# using a dplyr approach
stations %>% distinct(___) %>% tally() 

```


```{r sta-query-solution}

stations %>% distinct(ZIP) %>% tally() # same!

```

To answer the third question, which zip code has the most groundwater stations present, we need to sort our data somehow from largest (the most) to smallest (fewwest) number of groundwater stations per zip code.

```{r sta-query2, exercise = TRUE}

stations %>% group_by(___) %>% 
  tally() %>% 
  arrange(___)

```

```{r sta-query2-hint-1}

stations %>% 
  group_by(ZIP) %>% 
  tally() %>% 
  arrange(___(n))

```

```{r sta-query2-solution}

stations %>% 
  group_by(ZIP) %>% 
  tally() %>% 
  arrange(desc(n)) 
# so top row in this is ZIP 95693 with 37 stations.


```

## Shapefiles

We want to import a shapefile (currently zipped, but accessible at the link below). This may require downloading and saving to your computer directly, or look in unzipped data folder from previous lessons.

```{r, echo=TRUE, eval=FALSE}

# download (change destfile to local dir in your project!)
download.file(url = "https://github.com/r4wrds/r4wrds/raw/worksheet-wrangling/intro/data/calenviroscreen/CES3_shp.zip", destfile = "worksheets/CES3_shp.zip")

# unzip to dir of your choice with "exdir"
unzip("worksheets/CES3_shp.zip", exdir = "worksheets")

# import to R as sf
library(sf)
shpfile <- st_read(here("worksheets/CES3_shp/CES3June2018Update.shp"))

```


## Filter and Plot

Filter to just the zip code with the most groundwater stations from sac dataset and plot.

```{r}

shpfile %>% filter(ZIP %in% 95693) -> shp_trim 

# make stations sf

plot(shp_trim) + plot(stations)
```



